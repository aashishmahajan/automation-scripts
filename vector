import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from sklearn.feature_selection import SelectKBest, f_classif


# Assuming 'data.csv' is your CSV file
df = pd.read_csv('data.csv')

# Clean text if applicable
text_columns = ['column1', 'column2']  # Example text columns
for col in text_columns:
    df[col] = df[col].str.lower().str.replace('[^\w\s]', '', regex=True)




# Vectorize text data
tfidf_vectorizer = TfidfVectorizer(max_features=1000)
for col in text_columns:
    tfidf_matrix = tfidf_vectorizer.fit_transform(df[col])
    # Convert sparse matrix to dataframe
    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_vectorizer.get_feature_names_out())
    df = pd.concat([df, tfidf_df], axis=1).drop(columns=[col])

# Encode other categorical variables
le = LabelEncoder()
for col in df.select_dtypes(include=['object']).columns:
    df[col] = le.fit_transform(df[col])




# Assuming 'root_cause' is your target variable
X = df.drop('root_cause', axis=1)
y = df['root_cause']

# Selecting top 10 features based on ANOVA F-value
selector = SelectKBest(f_classif, k=10)
X_new = selector.fit_transform(X, y)
cols = selector.get_support(indices=True)
selected_features = X.columns[cols].tolist()





from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=42)

rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

y_pred = rf.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))




importances = rf.feature_importances_
feature_importance = pd.DataFrame({'feature': selected_features, 'importance': importances})
print(feature_importance.sort_values('importance', ascending=False))
